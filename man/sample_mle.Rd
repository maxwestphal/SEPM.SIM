% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sample_mle.R
\name{sample_mle}
\alias{sample_mle}
\title{Generate artifical data and train prediction models}
\usage{
sample_mle(
  n.learn = 400,
  ratio.lv = 0.75,
  n.eval = 10000,
  n.pop = 1e+05,
  P = 50,
  red = 0,
  rho = 0.5,
  scenario = "EOMPM_A2",
  scenario.learn = scenario,
  methods = "glmnet_xgbTree_rpartCost_svmLinearWeights2",
  M = 50,
  tuning = "random",
  data = NULL,
  job = NULL
)
}
\arguments{
\item{n.learn}{integer, number of learning observations}

\item{ratio.lv}{numeric, fraction of learning observations to use for validation (default: 0.75)}

\item{n.eval}{integer, number of test observations}

\item{n.pop}{integer, population sample size (used to calculate 'true' performances)}

\item{P}{integer, total number of features (needs to be larger than active features of scenario)}

\item{red}{integer, set degree of redundancy among features (independent features with red=0)}

\item{rho}{numeric, (equi)correlation in (0,1) between redundant features (no effect if red=0)}

\item{scenario}{character, specifies data distribution scenario, e.g. "EOMPM_A2" (default)}

\item{scenario.learn}{character, potentially perturbed learning distribution, equalls scenario by default}

\item{methods}{character, specify learning algorithms and combinations thereof, e.g. "glmnet_xgbTree",
the following methods are supported: "glmnet", "xgbTree", "rpartCost", "svmLinearWeights2"
(see caret documentation; default: "glmnet_xgbTree_rpartCost_svmLinearWeights2")}

\item{M}{integer, number of models to train per learning algorithm (default: 50)}

\item{tuning}{character, specify hyperparameter sampling, either "random" (default) or "grid"}

\item{data}{NULL, batchtools argument}

\item{job}{NULL, batchtools argument}
}
\value{
Returns a data instance which is processed by either the study_mle_acc() or theory().
}
\description{
This function is used to generate artifical observations of feature-label pairs which are then
used to train prediction models by various machine learning algorithms.
}
